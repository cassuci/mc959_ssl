{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_npy_image(file_path):\n",
    "    \"\"\"Load a .npy image file.\"\"\"\n",
    "    try:\n",
    "        return np.load(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None  # Return None if loading fails\n",
    "\n",
    "def resize_image(image, size=(224, 224)):\n",
    "    \"\"\"Resize an image to a given size.\"\"\"\n",
    "    resized_image = tf.image.resize(image, size)\n",
    "    return resized_image.numpy()  # Convert to NumPy array after resizing\n",
    "\n",
    "def normalize_image(image):\n",
    "    \"\"\"Normalize image values to range [0, 1].\"\"\"\n",
    "    if image is not None:\n",
    "        return image.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "    return None\n",
    "\n",
    "def load_and_preprocess_images(data_dir, num_samples=5):\n",
    "    \"\"\"Load and preprocess images for the inpainting task.\"\"\"\n",
    "    masked_files = sorted(\n",
    "        [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.startswith(\"masked_\")]\n",
    "    )\n",
    "    \n",
    "    images = []\n",
    "    for i, file_path in enumerate(masked_files[:num_samples]):\n",
    "        img = load_npy_image(file_path)\n",
    "        print(img.shape)\n",
    "        if img is not None:\n",
    "            img = resize_image(img)\n",
    "            img = normalize_image(img)\n",
    "            images.append(img)\n",
    "            # Check dimensions for compatibility\n",
    "            check_image_dimensions(img)\n",
    "        else:\n",
    "            print(f\"Skipping {file_path} due to loading error.\")\n",
    "\n",
    "    return images\n",
    "\n",
    "def check_image_dimensions(image):\n",
    "    \"\"\"Check if the image has the correct dimensions.\"\"\"\n",
    "    if image.ndim != 3 or image.shape[-1] != 3:\n",
    "        raise ValueError(f\"Image dimensions are not compatible: {image.shape}. Expected shape: [height, width, 3]\")\n",
    "\n",
    "def display_images(images):\n",
    "    \"\"\"Display images in a grid.\"\"\"\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, img in enumerate(images):\n",
    "        plt.subplot(1, len(images), i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxoAAABVCAYAAADOppJ2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACEElEQVR4nO3dQQrCQBBFQUe8/5XbhReIzRNRqtZZDJ9AeMwiZ2bmBgAAELp/+wAAAMD/ERoAAEBOaAAAADmhAQAA5IQGAACQExoAAEBOaAAAADmhAQAA5B5XHzznfPIcP2Pzf0Pbvdhu793t7Pbinduz3Z7t9my3Z7s939idK7u50QAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJnZubbhwAAAP6LGw0AACAnNAAAgJzQAAAAckIDAADICQ0AACAnNAAAgJzQAAAAckIDAADICQ0AACD3BFqNJqNPUOCiAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x1000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dir = r\"F:\\ssl_images\\data\\processed\\coco\\inpainting\"  # Use raw string\n",
    "images = load_and_preprocess_images(data_dir, 10)\n",
    "display_images(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.io.read_file(r\"F:\\ssl_images\\data\\processed\\coco\\inpainting\\masked_0.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
