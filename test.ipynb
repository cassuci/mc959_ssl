{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_npy_image(file_path):\n",
    "    \"\"\"Load a .npy image file.\"\"\"\n",
    "    try:\n",
    "        return np.load(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None  # Return None if loading fails\n",
    "\n",
    "def resize_image(image, size=(224, 224)):\n",
    "    \"\"\"Resize an image to a given size.\"\"\"\n",
    "    resized_image = tf.image.resize(image, size)\n",
    "    return resized_image.numpy()  # Convert to NumPy array after resizing\n",
    "\n",
    "def normalize_image(image):\n",
    "    \"\"\"Normalize image values to range [0, 1].\"\"\"\n",
    "    if image is not None:\n",
    "        return image.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "    return None\n",
    "\n",
    "def load_and_preprocess_images(data_dir, num_samples=5):\n",
    "    \"\"\"Load and preprocess images for the inpainting task.\"\"\"\n",
    "    masked_files = sorted(\n",
    "        [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.startswith(\"masked_\")]\n",
    "    )\n",
    "    \n",
    "    images = []\n",
    "    for i, file_path in enumerate(masked_files[:num_samples]):\n",
    "        img = load_npy_image(file_path)\n",
    "        print(img.shape)\n",
    "        if img is not None:\n",
    "            img = resize_image(img)\n",
    "            img = normalize_image(img)\n",
    "            images.append(img)\n",
    "            # Check dimensions for compatibility\n",
    "            check_image_dimensions(img)\n",
    "        else:\n",
    "            print(f\"Skipping {file_path} due to loading error.\")\n",
    "\n",
    "    return images\n",
    "\n",
    "def check_image_dimensions(image):\n",
    "    \"\"\"Check if the image has the correct dimensions.\"\"\"\n",
    "    if image.ndim != 3 or image.shape[-1] != 3:\n",
    "        raise ValueError(f\"Image dimensions are not compatible: {image.shape}. Expected shape: [height, width, 3]\")\n",
    "\n",
    "def display_images(images):\n",
    "    \"\"\"Display images in a grid.\"\"\"\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, img in enumerate(images):\n",
    "        plt.subplot(1, len(images), i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxoAAABVCAYAAADOppJ2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACEElEQVR4nO3dQQrCQBBFQUe8/5XbhReIzRNRqtZZDJ9AeMwiZ2bmBgAAELp/+wAAAMD/ERoAAEBOaAAAADmhAQAA5IQGAACQExoAAEBOaAAAADmhAQAA5B5XHzznfPIcP2Pzf0Pbvdhu793t7Pbinduz3Z7t9my3Z7s939idK7u50QAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJnZubbhwAAAP6LGw0AACAnNAAAgJzQAAAAckIDAADICQ0AACAnNAAAgJzQAAAAckIDAADICQ0AACD3BFqNJqNPUOCiAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x1000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dir = r\"F:\\ssl_images\\data\\processed\\coco\\inpainting\"  # Use raw string\n",
    "images = load_and_preprocess_images(data_dir, 10)\n",
    "display_images(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.io.read_file(r\"F:\\ssl_images\\data\\processed\\coco\\inpainting\\masked_0.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Resnet18' from 'src.models.resnet' (c:\\Users\\gabri\\Desktop\\UNICAMP\\ssl_discipline\\self_supervised_learning_project\\src\\models\\resnet.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")))\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ResNet50, Resnet18\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_and_preprocess_image\u001b[39m(image_path):\n\u001b[0;32m     14\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load and preprocess a single image for colorization.\"\"\"\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Resnet18' from 'src.models.resnet' (c:\\Users\\gabri\\Desktop\\UNICAMP\\ssl_discipline\\self_supervised_learning_project\\src\\models\\resnet.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "#sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")))\n",
    "from src.models.resnet import ResNet50, Resnet18\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    \"\"\"Load and preprocess a single image for colorization.\"\"\"\n",
    "    # Load image\n",
    "    img = np.load(image_path)\n",
    "    \n",
    "    # Convert to float and normalize\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    \n",
    "    # Ensure grayscale input\n",
    "    if len(img.shape) == 3 and img.shape[-1] == 3:\n",
    "        img = tf.image.rgb_to_grayscale(img)\n",
    "    \n",
    "    # Add batch dimension\n",
    "    img = tf.expand_dims(img, 0)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def visualize_colorization(model_path, image_path):\n",
    "    \"\"\"Load model, process image, and visualize results.\"\"\"\n",
    "    # Initialize model\n",
    "    model = Resnet18((224, 224, 1))\n",
    "    \n",
    "    # Load trained weights\n",
    "    model.load_weights(model_path)\n",
    "    \n",
    "    # Load and preprocess input image\n",
    "    input_image = load_and_preprocess_image(image_path)\n",
    "    \n",
    "    # Get model prediction\n",
    "    predicted_color = model.predict(input_image)\n",
    "    \n",
    "    # Remove batch dimension\n",
    "    input_image = tf.squeeze(input_image)\n",
    "    predicted_color = tf.squeeze(predicted_color) * 255.0\n",
    "    \n",
    "    # Load original color image for comparison\n",
    "    color_path = image_path.replace('gray', 'color')\n",
    "    original_color = np.load(color_path)\n",
    "    original_color = original_color.astype(np.float32) #/ 255.0\n",
    "    \n",
    "    # Create figure with three subplots\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot grayscale input\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(input_image, cmap='gray')\n",
    "    plt.title('Grayscale Input')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Plot model prediction\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(predicted_color)\n",
    "    plt.title('Model Colorization')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Plot original color image\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(original_color)\n",
    "    plt.title('Original Color')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some statistics\n",
    "    mae = tf.reduce_mean(tf.abs(original_color - predicted_color))\n",
    "    mse = tf.reduce_mean(tf.square(original_color - predicted_color))\n",
    "    print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "    print(f\"Mean Absolute Error: {mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\ssl_images\\data\\processed\\coco\\colorization\\gray_55.npy\n",
      "Running colorization inference...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'models\\checkpoints_resnet\\model_epoch_006.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_image)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning colorization inference...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m \u001b[43mvisualize_colorization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisualization complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 36\u001b[0m, in \u001b[0;36mvisualize_colorization\u001b[1;34m(model_path, image_path)\u001b[0m\n\u001b[0;32m     33\u001b[0m model \u001b[38;5;241m=\u001b[39m ResNet50((\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Load trained weights\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Load and preprocess input image\u001b[39;00m\n\u001b[0;32m     39\u001b[0m input_image \u001b[38;5;241m=\u001b[39m load_and_preprocess_image(image_path)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\h5py\\_hl\\files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'models\\checkpoints_resnet\\model_epoch_006.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# Set up paths\n",
    "model_path = os.path.join(\"models\", \"checkpoints\", \"model_epoch_006.h5\")\n",
    "data_dir = os.path.join(\"F:\\\\ssl_images\\\\data\", \"processed\", \"coco\", 'colorization')\n",
    "\n",
    "# Get a test image path (using the first grayscale image in the directory)\n",
    "test_image = next(\n",
    "    os.path.join(data_dir, f) \n",
    "    for f in os.listdir(data_dir) \n",
    "    if f.startswith(\"gray\")\n",
    ")\n",
    "test_image = test_image.replace('_0', '_55')\n",
    "print(test_image)\n",
    "\n",
    "print(\"Running colorization inference...\")\n",
    "visualize_colorization(model_path, test_image)\n",
    "print(\"Visualization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "from src.models.resnet import ResNet18, ResNet50\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    \"\"\"Load and preprocess a single image for inpainting.\"\"\"\n",
    "    # Load image\n",
    "    img = np.load(image_path)\n",
    "    \n",
    "    # Convert to float and normalize\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    \n",
    "    # Add batch dimension\n",
    "    img = tf.expand_dims(img, 0)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def visualize_inpainting(model_path, image_path):\n",
    "    \"\"\"Load model, process image, and visualize inpainting results.\"\"\"\n",
    "    # Initialize model\n",
    "    model = ResNet18((224, 224, 3))\n",
    "    \n",
    "    # Load trained weights\n",
    "    model.load_weights(model_path)\n",
    "    \n",
    "    # Load and preprocess masked image\n",
    "    masked_image = load_and_preprocess_image(image_path)\n",
    "    \n",
    "    # Get model prediction\n",
    "    predicted_image = model.predict(masked_image)\n",
    "    \n",
    "    # Remove batch dimension\n",
    "    masked_image = tf.squeeze(masked_image) * 255.0\n",
    "    predicted_image = tf.squeeze(predicted_image) * 255.0\n",
    "    \n",
    "    # Load original image for comparison\n",
    "    original_path = image_path.replace('masked', 'original')\n",
    "    original_image = np.load(original_path)\n",
    "    original_image = original_image.astype(np.float32) #/ 255.0\n",
    "    \n",
    "    # Create figure with three subplots\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot masked input\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(masked_image)\n",
    "    plt.title('Masked Input')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Plot model prediction\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(predicted_image)\n",
    "    plt.title('Inpainted Result')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Plot original image\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(original_image)\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate and print metrics\n",
    "    mse = tf.reduce_mean(tf.square(original_image - predicted_image))\n",
    "    mae = tf.reduce_mean(tf.abs(original_image - predicted_image))\n",
    "    psnr = tf.image.psnr(original_image, predicted_image, max_val=1.0)\n",
    "    ssim = tf.image.ssim(original_image, predicted_image, max_val=1.0)\n",
    "    \n",
    "    print(\"\\nImage Quality Metrics:\")\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "    print(f\"Peak Signal-to-Noise Ratio: {psnr:.2f} dB\")\n",
    "    print(f\"Structural Similarity Index: {ssim:.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def visualize_multiple_samples(model_path, data_dir, num_samples=5):\n",
    "    \"\"\"Visualize multiple inpainting results.\"\"\"\n",
    "    # Get list of masked images\n",
    "    masked_files = [f for f in os.listdir(data_dir) if f.startswith(\"masked\")][:num_samples]\n",
    "    \n",
    "    # Load model once\n",
    "    model = ResNet18((224, 224, 3))\n",
    "    model.load_weights(model_path)\n",
    "    \n",
    "    for masked_file in masked_files:\n",
    "        print(f\"\\nProcessing {masked_file}...\")\n",
    "        image_path = os.path.join(data_dir, masked_file)\n",
    "        \n",
    "        # Load images\n",
    "        masked_image = load_and_preprocess_image(image_path)\n",
    "        predicted_image = model.predict(masked_image) \n",
    "        \n",
    "        original_path = image_path.replace('masked', 'original')\n",
    "        original_image = np.load(original_path)\n",
    "        original_image = original_image.astype(np.float32) #/ 255.0\n",
    "        \n",
    "        # Remove batch dimensions\n",
    "        masked_image = tf.squeeze(masked_image) * 255.0\n",
    "        predicted_image = tf.squeeze(predicted_image) * 255.0\n",
    "        \n",
    "        # Visualize\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(masked_image)\n",
    "        plt.title('Masked Input')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(predicted_image)\n",
    "        plt.title('Inpainted Result')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(original_image)\n",
    "        plt.title('Original Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print metrics\n",
    "        psnr = tf.image.psnr(original_image, predicted_image, max_val=1.0)\n",
    "        ssim = tf.image.ssim(original_image, predicted_image, max_val=1.0)\n",
    "        print(f\"PSNR: {psnr:.2f} dB\")\n",
    "        print(f\"SSIM: {ssim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'models\\inpainting_model_final.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# For single image visualization:\u001b[39;00m\n\u001b[0;32m      6\u001b[0m test_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m      7\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, f) \n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(data_dir) \n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmasked\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m )\n\u001b[1;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mvisualize_inpainting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# For multiple images visualization:\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mVisualizing multiple samples...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 28\u001b[0m, in \u001b[0;36mvisualize_inpainting\u001b[1;34m(model_path, image_path)\u001b[0m\n\u001b[0;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m ResNet18((\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Load trained weights\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Load and preprocess masked image\u001b[39;00m\n\u001b[0;32m     31\u001b[0m masked_image \u001b[38;5;241m=\u001b[39m load_and_preprocess_image(image_path)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\h5py\\_hl\\files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'models\\inpainting_model_final.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage in notebook:\n",
    "model_path = os.path.join(\"models\", \"inpainting_model_final.h5\")\n",
    "data_dir = os.path.join(\"F:\\\\ssl_images\\\\data\", \"processed\", \"coco\", 'inpainting')\n",
    "\n",
    "# For single image visualization:\n",
    "test_image = next(\n",
    "    os.path.join(data_dir, f) \n",
    "    for f in os.listdir(data_dir) \n",
    "    if f.startswith(\"masked\")\n",
    ")\n",
    "model = visualize_inpainting(model_path, test_image)\n",
    "\n",
    "# For multiple images visualization:\n",
    "print(\"\\nVisualizing multiple samples...\")\n",
    "visualize_multiple_samples(model_path, data_dir, num_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from PIL import Image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "from src.models.resnet import ResNet18, ResNet50  # Import your ResNet implementation\n",
    "\n",
    "def initialize_model(input_shape):\n",
    "    \"\"\"Initialize the ResNet model.\"\"\"\n",
    "    return ResNet50(input_shape)\n",
    "\n",
    "def generate_sample_data(batch_size=4, img_size=(224, 224), channels=3):\n",
    "    \"\"\"Generate a batch of random images.\"\"\"\n",
    "    return tf.random.uniform((batch_size, *img_size, channels), minval=0, maxval=1)\n",
    "\n",
    "def test_and_plot(model, batch_size=4, img_size=(224, 224), channels=3):\n",
    "    \"\"\"Test the model and plot the results.\"\"\"\n",
    "    input_data = generate_sample_data(batch_size=batch_size, img_size=img_size, channels=channels)\n",
    "    \n",
    "    # Build the model by running a sample input through it\n",
    "    sample_input = tf.keras.Input(shape=(img_size[0], img_size[1], channels))\n",
    "    _ = model(sample_input)\n",
    "\n",
    "    # Plot the model architecture and save it as an image\n",
    "    plot_model(model, to_file=\"resnet_model_architecture.png\", show_shapes=True, expand_nested=True)\n",
    "\n",
    "    # Get model output\n",
    "    output_data = model(input_data)\n",
    "\n",
    "    # Save input and output images\n",
    "    os.makedirs(\"output_images\", exist_ok=True)  # Create directory for output images\n",
    "    for i in range(batch_size):\n",
    "        # Save input image\n",
    "        input_image = (input_data[i].numpy() * 255).astype('uint8')  # Convert to uint8 for saving\n",
    "        plt.imsave(f\"output_images/input_image_{i}.png\", input_image)\n",
    "\n",
    "        # Save output image\n",
    "        output_image = (output_data[i].numpy() * 255).astype('uint8')  # Convert to uint8 for saving\n",
    "        plt.imsave(f\"output_images/output_image_{i}.png\", output_image)\n",
    "\n",
    "def load_model_weights(model, save_path):\n",
    "    \"\"\"Load model weights from the specified path.\"\"\"\n",
    "    model.load_weights(save_path)\n",
    "    print(f\"Model weights loaded from {save_path}\")\n",
    "\n",
    "\n",
    "# Test RGB images with 3 channel ResNet\n",
    "model_rgb = initialize_model((224, 224, 3))  # RGB\n",
    "test_and_plot(model_rgb, batch_size=4, img_size=(224, 224), channels=3)\n",
    "\n",
    "# Test grayscale images with 1 channel ResNet\n",
    "#model_gray = initialize_model((224, 224, 1))  # Grayscale\n",
    "#test_and_plot(model_gray, batch_size=4, img_size=(224, 224), channels=1)\n",
    "\n",
    "#model_load = initialize_model((224, 224, 1))\n",
    "                                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet18\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)              (None, 112, 112, 64)         9472      ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)    (None, 112, 112, 64)         256       ['conv1[0][0]']               \n",
      "                                                                                                  \n",
      " leaky_re_lu_34 (LeakyReLU)  (None, 112, 112, 64)         0         ['bn1[0][0]']                 \n",
      "                                                                                                  \n",
      " block_0_0 (ResNetBlock)     (None, 56, 56, 64)           78784     ['leaky_re_lu_34[0][0]']      \n",
      "                                                                                                  \n",
      " block_0_1 (ResNetBlock)     (None, 56, 56, 64)           74368     ['block_0_0[0][0]']           \n",
      "                                                                                                  \n",
      " block_1_0 (ResNetBlock)     (None, 28, 28, 128)          231296    ['block_0_1[0][0]']           \n",
      "                                                                                                  \n",
      " block_1_1 (ResNetBlock)     (None, 28, 28, 128)          313216    ['block_1_0[0][0]']           \n",
      "                                                                                                  \n",
      " block_2_0 (ResNetBlock)     (None, 14, 14, 256)          921344    ['block_1_1[0][0]']           \n",
      "                                                                                                  \n",
      " block_2_1 (ResNetBlock)     (None, 14, 14, 256)          1249024   ['block_2_0[0][0]']           \n",
      "                                                                                                  \n",
      " block_3_0 (ResNetBlock)     (None, 7, 7, 512)            3677696   ['block_2_1[0][0]']           \n",
      "                                                                                                  \n",
      " block_3_1 (ResNetBlock)     (None, 7, 7, 512)            4988416   ['block_3_0[0][0]']           \n",
      "                                                                                                  \n",
      " decoder_0_upsample (UpSamp  (None, 14, 14, 512)          0         ['block_3_1[0][0]']           \n",
      " ling2D)                                                                                          \n",
      "                                                                                                  \n",
      " decoder_0_concat (Concaten  (None, 14, 14, 768)          0         ['decoder_0_upsample[0][0]',  \n",
      " ate)                                                                'block_2_1[0][0]']           \n",
      "                                                                                                  \n",
      " decoder_0_conv1 (Conv2D)    (None, 14, 14, 256)          1769728   ['decoder_0_concat[0][0]']    \n",
      "                                                                                                  \n",
      " decoder_0_bn1 (BatchNormal  (None, 14, 14, 256)          1024      ['decoder_0_conv1[0][0]']     \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " leaky_re_lu_43 (LeakyReLU)  (None, 14, 14, 256)          0         ['decoder_0_bn1[0][0]']       \n",
      "                                                                                                  \n",
      " decoder_0_conv2 (Conv2D)    (None, 14, 14, 256)          590080    ['leaky_re_lu_43[0][0]']      \n",
      "                                                                                                  \n",
      " decoder_0_bn2 (BatchNormal  (None, 14, 14, 256)          1024      ['decoder_0_conv2[0][0]']     \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " leaky_re_lu_44 (LeakyReLU)  (None, 14, 14, 256)          0         ['decoder_0_bn2[0][0]']       \n",
      "                                                                                                  \n",
      " decoder_1_upsample (UpSamp  (None, 28, 28, 256)          0         ['leaky_re_lu_44[0][0]']      \n",
      " ling2D)                                                                                          \n",
      "                                                                                                  \n",
      " decoder_1_concat (Concaten  (None, 28, 28, 384)          0         ['decoder_1_upsample[0][0]',  \n",
      " ate)                                                                'block_1_1[0][0]']           \n",
      "                                                                                                  \n",
      " decoder_1_conv1 (Conv2D)    (None, 28, 28, 128)          442496    ['decoder_1_concat[0][0]']    \n",
      "                                                                                                  \n",
      " decoder_1_bn1 (BatchNormal  (None, 28, 28, 128)          512       ['decoder_1_conv1[0][0]']     \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " leaky_re_lu_45 (LeakyReLU)  (None, 28, 28, 128)          0         ['decoder_1_bn1[0][0]']       \n",
      "                                                                                                  \n",
      " decoder_1_conv2 (Conv2D)    (None, 28, 28, 128)          147584    ['leaky_re_lu_45[0][0]']      \n",
      "                                                                                                  \n",
      " decoder_1_bn2 (BatchNormal  (None, 28, 28, 128)          512       ['decoder_1_conv2[0][0]']     \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " leaky_re_lu_46 (LeakyReLU)  (None, 28, 28, 128)          0         ['decoder_1_bn2[0][0]']       \n",
      "                                                                                                  \n",
      " decoder_2_upsample (UpSamp  (None, 56, 56, 128)          0         ['leaky_re_lu_46[0][0]']      \n",
      " ling2D)                                                                                          \n",
      "                                                                                                  \n",
      " decoder_2_concat (Concaten  (None, 56, 56, 192)          0         ['decoder_2_upsample[0][0]',  \n",
      " ate)                                                                'block_0_1[0][0]']           \n",
      "                                                                                                  \n",
      " decoder_2_conv1 (Conv2D)    (None, 56, 56, 64)           110656    ['decoder_2_concat[0][0]']    \n",
      "                                                                                                  \n",
      " decoder_2_bn1 (BatchNormal  (None, 56, 56, 64)           256       ['decoder_2_conv1[0][0]']     \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " leaky_re_lu_47 (LeakyReLU)  (None, 56, 56, 64)           0         ['decoder_2_bn1[0][0]']       \n",
      "                                                                                                  \n",
      " decoder_2_conv2 (Conv2D)    (None, 56, 56, 64)           36928     ['leaky_re_lu_47[0][0]']      \n",
      "                                                                                                  \n",
      " decoder_2_bn2 (BatchNormal  (None, 56, 56, 64)           256       ['decoder_2_conv2[0][0]']     \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " leaky_re_lu_48 (LeakyReLU)  (None, 56, 56, 64)           0         ['decoder_2_bn2[0][0]']       \n",
      "                                                                                                  \n",
      " decoder_3_upsample (UpSamp  (None, 112, 112, 64)         0         ['leaky_re_lu_48[0][0]']      \n",
      " ling2D)                                                                                          \n",
      "                                                                                                  \n",
      " decoder_3_concat (Concaten  (None, 112, 112, 128)        0         ['decoder_3_upsample[0][0]',  \n",
      " ate)                                                                'leaky_re_lu_34[0][0]']      \n",
      "                                                                                                  \n",
      " decoder_3_conv1 (Conv2D)    (None, 112, 112, 32)         36896     ['decoder_3_concat[0][0]']    \n",
      "                                                                                                  \n",
      " decoder_3_bn1 (BatchNormal  (None, 112, 112, 32)         128       ['decoder_3_conv1[0][0]']     \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " leaky_re_lu_49 (LeakyReLU)  (None, 112, 112, 32)         0         ['decoder_3_bn1[0][0]']       \n",
      "                                                                                                  \n",
      " decoder_3_conv2 (Conv2D)    (None, 112, 112, 32)         9248      ['leaky_re_lu_49[0][0]']      \n",
      "                                                                                                  \n",
      " decoder_3_bn2 (BatchNormal  (None, 112, 112, 32)         128       ['decoder_3_conv2[0][0]']     \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " leaky_re_lu_50 (LeakyReLU)  (None, 112, 112, 32)         0         ['decoder_3_bn2[0][0]']       \n",
      "                                                                                                  \n",
      " decoder_4_upsample (UpSamp  (None, 224, 224, 32)         0         ['leaky_re_lu_50[0][0]']      \n",
      " ling2D)                                                                                          \n",
      "                                                                                                  \n",
      " decoder_4_conv1 (Conv2D)    (None, 224, 224, 16)         4624      ['decoder_4_upsample[0][0]']  \n",
      "                                                                                                  \n",
      " decoder_4_bn1 (BatchNormal  (None, 224, 224, 16)         64        ['decoder_4_conv1[0][0]']     \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " leaky_re_lu_51 (LeakyReLU)  (None, 224, 224, 16)         0         ['decoder_4_bn1[0][0]']       \n",
      "                                                                                                  \n",
      " decoder_4_conv2 (Conv2D)    (None, 224, 224, 16)         2320      ['leaky_re_lu_51[0][0]']      \n",
      "                                                                                                  \n",
      " decoder_4_bn2 (BatchNormal  (None, 224, 224, 16)         64        ['decoder_4_conv2[0][0]']     \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " leaky_re_lu_52 (LeakyReLU)  (None, 224, 224, 16)         0         ['decoder_4_bn2[0][0]']       \n",
      "                                                                                                  \n",
      " pre_output_conv (Conv2D)    (None, 224, 224, 8)          1160      ['leaky_re_lu_52[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_53 (LeakyReLU)  (None, 224, 224, 8)          0         ['pre_output_conv[0][0]']     \n",
      "                                                                                                  \n",
      " output_conv (Conv2D)        (None, 224, 224, 3)          219       ['leaky_re_lu_53[0][0]']      \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TF  (None, 224, 224, 3)          0         ['output_conv[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.math.truediv_2 (TFOpLam  (None, 224, 224, 3)          0         ['tf.__operators__.add_2[0][0]\n",
      " bda)                                                               ']                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14699779 (56.08 MB)\n",
      "Trainable params: 14686275 (56.02 MB)\n",
      "Non-trainable params: 13504 (52.75 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from src.models.resnet import ResNet18, ResNet50  # Import your ResNet implementation\n",
    "\n",
    "model = ResNet18((224, 224, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ResNet50\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Carregar o modelo ResNet50 com pesos pré-treinados\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\__init__.py:478\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;66;03m# Do an eager load for Keras' code so that any function/method that needs to\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;66;03m# happen at load time will trigger, eg registration of optimizers in the\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;66;03m# SavedModel registry.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# See b/196254385 for more details.\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m   \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeras.optimizers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[0;32m    480\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\__internal__\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\__internal__\\backend\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _initialize_variables \u001b[38;5;28;01mas\u001b[39;00m initialize_variables\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m track_variable\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\models\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Functional\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\functional.py:33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_spec\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m node \u001b[38;5;28;01mas\u001b[39;00m node_module\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training \u001b[38;5;28;01mas\u001b[39;00m training_lib\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training_utils\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization_lib\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer_utils\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compile_utils\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_adapter\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_layer \u001b[38;5;28;01mas\u001b[39;00m input_layer_module\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses \u001b[38;5;28;01mas\u001b[39;00m losses_mod\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics \u001b[38;5;28;01mas\u001b[39;00m metrics_mod\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saving_lib\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generic_utils\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\metrics\\__init__.py:87\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregression_metrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_logarithmic_error\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Confusion metrics\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfusion_metrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AUC\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfusion_metrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FalseNegatives\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfusion_metrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FalsePositives\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\metrics\\confusion_metrics.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils \u001b[38;5;28;01mas\u001b[39;00m dtensor_utils\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\activations.py:22\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivation\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mactivation_layers\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m object_registration\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\__init__.py:86\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlocally_connected\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlocally_connected2d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     81\u001b[0m     LocallyConnected2D,\n\u001b[0;32m     82\u001b[0m )\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Merging functions.\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Merging layers.\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Add\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m add\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maverage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Average\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\merging\\__init__.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maverage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Average\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maverage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m average\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcatenate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Concatenate\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcatenate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concatenate\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dot\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:936\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1032\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1130\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "# Carregar o modelo ResNet50 com pesos pré-treinados\n",
    "model = ResNet50()\n",
    "\n",
    "# Imprimir o resumo do modelo\n",
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
