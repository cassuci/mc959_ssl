{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_npy_image(file_path):\n",
    "    \"\"\"Load a .npy image file.\"\"\"\n",
    "    try:\n",
    "        return np.load(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None  # Return None if loading fails\n",
    "\n",
    "def resize_image(image, size=(224, 224)):\n",
    "    \"\"\"Resize an image to a given size.\"\"\"\n",
    "    resized_image = tf.image.resize(image, size)\n",
    "    return resized_image.numpy()  # Convert to NumPy array after resizing\n",
    "\n",
    "def normalize_image(image):\n",
    "    \"\"\"Normalize image values to range [0, 1].\"\"\"\n",
    "    if image is not None:\n",
    "        return image.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "    return None\n",
    "\n",
    "def load_and_preprocess_images(data_dir, num_samples=5):\n",
    "    \"\"\"Load and preprocess images for the inpainting task.\"\"\"\n",
    "    masked_files = sorted(\n",
    "        [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.startswith(\"masked_\")]\n",
    "    )\n",
    "    \n",
    "    images = []\n",
    "    for i, file_path in enumerate(masked_files[:num_samples]):\n",
    "        img = load_npy_image(file_path)\n",
    "        print(img.shape)\n",
    "        if img is not None:\n",
    "            img = resize_image(img)\n",
    "            img = normalize_image(img)\n",
    "            images.append(img)\n",
    "            # Check dimensions for compatibility\n",
    "            check_image_dimensions(img)\n",
    "        else:\n",
    "            print(f\"Skipping {file_path} due to loading error.\")\n",
    "\n",
    "    return images\n",
    "\n",
    "def check_image_dimensions(image):\n",
    "    \"\"\"Check if the image has the correct dimensions.\"\"\"\n",
    "    if image.ndim != 3 or image.shape[-1] != 3:\n",
    "        raise ValueError(f\"Image dimensions are not compatible: {image.shape}. Expected shape: [height, width, 3]\")\n",
    "\n",
    "def display_images(images):\n",
    "    \"\"\"Display images in a grid.\"\"\"\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, img in enumerate(images):\n",
    "        plt.subplot(1, len(images), i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxoAAABVCAYAAADOppJ2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACEElEQVR4nO3dQQrCQBBFQUe8/5XbhReIzRNRqtZZDJ9AeMwiZ2bmBgAAELp/+wAAAMD/ERoAAEBOaAAAADmhAQAA5IQGAACQExoAAEBOaAAAADmhAQAA5B5XHzznfPIcP2Pzf0Pbvdhu793t7Pbinduz3Z7t9my3Z7s939idK7u50QAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJnZubbhwAAAP6LGw0AACAnNAAAgJzQAAAAckIDAADICQ0AACAnNAAAgJzQAAAAckIDAADICQ0AACD3BFqNJqNPUOCiAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x1000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dir = r\"F:\\ssl_images\\data\\processed\\coco\\inpainting\"  # Use raw string\n",
    "images = load_and_preprocess_images(data_dir, 10)\n",
    "display_images(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.io.read_file(r\"F:\\ssl_images\\data\\processed\\coco\\inpainting\\masked_0.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "#sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")))\n",
    "from src.models.resnet import ResNet18\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    \"\"\"Load and preprocess a single image for colorization.\"\"\"\n",
    "    # Load image\n",
    "    img = np.load(image_path)\n",
    "    \n",
    "    # Convert to float and normalize\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    \n",
    "    # Ensure grayscale input\n",
    "    if len(img.shape) == 3 and img.shape[-1] == 3:\n",
    "        img = tf.image.rgb_to_grayscale(img)\n",
    "    \n",
    "    # Add batch dimension\n",
    "    img = tf.expand_dims(img, 0)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def visualize_colorization(model_path, image_path):\n",
    "    \"\"\"Load model, process image, and visualize results.\"\"\"\n",
    "    # Initialize model\n",
    "    model = ResNet18((224, 224, 1))\n",
    "    \n",
    "    # Load trained weights\n",
    "    model.load_weights(model_path)\n",
    "    \n",
    "    # Load and preprocess input image\n",
    "    input_image = load_and_preprocess_image(image_path)\n",
    "    \n",
    "    # Get model prediction\n",
    "    predicted_color = model.predict(input_image)\n",
    "    \n",
    "    # Remove batch dimension\n",
    "    input_image = tf.squeeze(input_image)\n",
    "    predicted_color = tf.squeeze(predicted_color) * 255.0\n",
    "    \n",
    "    # Load original color image for comparison\n",
    "    color_path = image_path.replace('gray', 'color')\n",
    "    original_color = np.load(color_path)\n",
    "    original_color = original_color.astype(np.float32) #/ 255.0\n",
    "    \n",
    "    # Create figure with three subplots\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot grayscale input\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(input_image, cmap='gray')\n",
    "    plt.title('Grayscale Input')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Plot model prediction\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(predicted_color)\n",
    "    plt.title('Model Colorization')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Plot original color image\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(original_color)\n",
    "    plt.title('Original Color')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some statistics\n",
    "    mae = tf.reduce_mean(tf.abs(original_color - predicted_color))\n",
    "    print(f\"Mean Absolute Error: {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Set up paths\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolorization_model_final.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mssl_images\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoco\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolorization\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Get a test image path (using the first grayscale image in the directory)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Set up paths\n",
    "model_path = os.path.join(\"models\", \"colorization_model_final.h5\")\n",
    "data_dir = os.path.join(\"F:\\\\ssl_images\\\\data\", \"processed\", \"coco\", 'colorization')\n",
    "\n",
    "# Get a test image path (using the first grayscale image in the directory)\n",
    "test_image = next(\n",
    "    os.path.join(data_dir, f) \n",
    "    for f in os.listdir(data_dir) \n",
    "    if f.startswith(\"gray\")\n",
    ")\n",
    "test_image = test_image.replace('_0', '_785')\n",
    "print(test_image)\n",
    "\n",
    "print(\"Running colorization inference...\")\n",
    "visualize_colorization(model_path, test_image)\n",
    "print(\"Visualization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "from src.models.resnet import ResNet18\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    \"\"\"Load and preprocess a single image for inpainting.\"\"\"\n",
    "    # Load image\n",
    "    img = np.load(image_path)\n",
    "    \n",
    "    # Convert to float and normalize\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    \n",
    "    # Add batch dimension\n",
    "    img = tf.expand_dims(img, 0)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def visualize_inpainting(model_path, image_path):\n",
    "    \"\"\"Load model, process image, and visualize inpainting results.\"\"\"\n",
    "    # Initialize model\n",
    "    model = ResNet18((224, 224, 3))\n",
    "    \n",
    "    # Load trained weights\n",
    "    model.load_weights(model_path)\n",
    "    \n",
    "    # Load and preprocess masked image\n",
    "    masked_image = load_and_preprocess_image(image_path)\n",
    "    \n",
    "    # Get model prediction\n",
    "    predicted_image = model.predict(masked_image)\n",
    "    \n",
    "    # Remove batch dimension\n",
    "    masked_image = tf.squeeze(masked_image) * 255.0\n",
    "    predicted_image = tf.squeeze(predicted_image) * 255.0\n",
    "    \n",
    "    # Load original image for comparison\n",
    "    original_path = image_path.replace('masked', 'original')\n",
    "    original_image = np.load(original_path)\n",
    "    original_image = original_image.astype(np.float32) #/ 255.0\n",
    "    \n",
    "    # Create figure with three subplots\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot masked input\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(masked_image)\n",
    "    plt.title('Masked Input')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Plot model prediction\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(predicted_image)\n",
    "    plt.title('Inpainted Result')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Plot original image\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(original_image)\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate and print metrics\n",
    "    mse = tf.reduce_mean(tf.square(original_image - predicted_image))\n",
    "    mae = tf.reduce_mean(tf.abs(original_image - predicted_image))\n",
    "    psnr = tf.image.psnr(original_image, predicted_image, max_val=1.0)\n",
    "    ssim = tf.image.ssim(original_image, predicted_image, max_val=1.0)\n",
    "    \n",
    "    print(\"\\nImage Quality Metrics:\")\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "    print(f\"Peak Signal-to-Noise Ratio: {psnr:.2f} dB\")\n",
    "    print(f\"Structural Similarity Index: {ssim:.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def visualize_multiple_samples(model_path, data_dir, num_samples=5):\n",
    "    \"\"\"Visualize multiple inpainting results.\"\"\"\n",
    "    # Get list of masked images\n",
    "    masked_files = [f for f in os.listdir(data_dir) if f.startswith(\"masked\")][:num_samples]\n",
    "    \n",
    "    # Load model once\n",
    "    model = ResNet18((224, 224, 3))\n",
    "    model.load_weights(model_path)\n",
    "    \n",
    "    for masked_file in masked_files:\n",
    "        print(f\"\\nProcessing {masked_file}...\")\n",
    "        image_path = os.path.join(data_dir, masked_file)\n",
    "        \n",
    "        # Load images\n",
    "        masked_image = load_and_preprocess_image(image_path)\n",
    "        predicted_image = model.predict(masked_image) \n",
    "        \n",
    "        original_path = image_path.replace('masked', 'original')\n",
    "        original_image = np.load(original_path)\n",
    "        original_image = original_image.astype(np.float32) #/ 255.0\n",
    "        \n",
    "        # Remove batch dimensions\n",
    "        masked_image = tf.squeeze(masked_image) * 255.0\n",
    "        predicted_image = tf.squeeze(predicted_image) * 255.0\n",
    "        \n",
    "        # Visualize\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(masked_image)\n",
    "        plt.title('Masked Input')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(predicted_image)\n",
    "        plt.title('Inpainted Result')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(original_image)\n",
    "        plt.title('Original Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print metrics\n",
    "        psnr = tf.image.psnr(original_image, predicted_image, max_val=1.0)\n",
    "        ssim = tf.image.ssim(original_image, predicted_image, max_val=1.0)\n",
    "        print(f\"PSNR: {psnr:.2f} dB\")\n",
    "        print(f\"SSIM: {ssim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'models\\inpainting_model_final.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# For single image visualization:\u001b[39;00m\n\u001b[0;32m      6\u001b[0m test_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m      7\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, f) \n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(data_dir) \n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmasked\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m )\n\u001b[1;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mvisualize_inpainting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# For multiple images visualization:\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mVisualizing multiple samples...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 28\u001b[0m, in \u001b[0;36mvisualize_inpainting\u001b[1;34m(model_path, image_path)\u001b[0m\n\u001b[0;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m ResNet18((\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Load trained weights\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Load and preprocess masked image\u001b[39;00m\n\u001b[0;32m     31\u001b[0m masked_image \u001b[38;5;241m=\u001b[39m load_and_preprocess_image(image_path)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\h5py\\_hl\\files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'models\\inpainting_model_final.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage in notebook:\n",
    "model_path = os.path.join(\"models\", \"inpainting_model_final.h5\")\n",
    "data_dir = os.path.join(\"F:\\\\ssl_images\\\\data\", \"processed\", \"coco\", 'inpainting')\n",
    "\n",
    "# For single image visualization:\n",
    "test_image = next(\n",
    "    os.path.join(data_dir, f) \n",
    "    for f in os.listdir(data_dir) \n",
    "    if f.startswith(\"masked\")\n",
    ")\n",
    "model = visualize_inpainting(model_path, test_image)\n",
    "\n",
    "# For multiple images visualization:\n",
    "print(\"\\nVisualizing multiple samples...\")\n",
    "visualize_multiple_samples(model_path, data_dir, num_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from PIL import Image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "from src.models.resnet import ResNet18  # Import your ResNet implementation\n",
    "\n",
    "def initialize_model(input_shape):\n",
    "    \"\"\"Initialize the ResNet model.\"\"\"\n",
    "    return ResNet18(input_shape)\n",
    "\n",
    "def generate_sample_data(batch_size=4, img_size=(224, 224), channels=3):\n",
    "    \"\"\"Generate a batch of random images.\"\"\"\n",
    "    return tf.random.uniform((batch_size, *img_size, channels), minval=0, maxval=1)\n",
    "\n",
    "def test_and_plot(model, batch_size=4, img_size=(224, 224), channels=3):\n",
    "    \"\"\"Test the model and plot the results.\"\"\"\n",
    "    input_data = generate_sample_data(batch_size=batch_size, img_size=img_size, channels=channels)\n",
    "    \n",
    "    # Build the model by running a sample input through it\n",
    "    sample_input = tf.keras.Input(shape=(img_size[0], img_size[1], channels))\n",
    "    _ = model(sample_input)\n",
    "\n",
    "    # Plot the model architecture and save it as an image\n",
    "    plot_model(model, to_file=\"resnet_model_architecture.png\", show_shapes=True, expand_nested=True)\n",
    "\n",
    "    # Get model output\n",
    "    output_data = model(input_data)\n",
    "\n",
    "    # Save input and output images\n",
    "    os.makedirs(\"output_images\", exist_ok=True)  # Create directory for output images\n",
    "    for i in range(batch_size):\n",
    "        # Save input image\n",
    "        input_image = (input_data[i].numpy() * 255).astype('uint8')  # Convert to uint8 for saving\n",
    "        plt.imsave(f\"output_images/input_image_{i}.png\", input_image)\n",
    "\n",
    "        # Save output image\n",
    "        output_image = (output_data[i].numpy() * 255).astype('uint8')  # Convert to uint8 for saving\n",
    "        plt.imsave(f\"output_images/output_image_{i}.png\", output_image)\n",
    "\n",
    "def load_model_weights(model, save_path):\n",
    "    \"\"\"Load model weights from the specified path.\"\"\"\n",
    "    model.load_weights(save_path)\n",
    "    print(f\"Model weights loaded from {save_path}\")\n",
    "\n",
    "\n",
    "# Test RGB images with 3 channel ResNet\n",
    "model_rgb = initialize_model((224, 224, 3))  # RGB\n",
    "test_and_plot(model_rgb, batch_size=4, img_size=(224, 224), channels=3)\n",
    "\n",
    "# Test grayscale images with 1 channel ResNet\n",
    "#model_gray = initialize_model((224, 224, 1))  # Grayscale\n",
    "#test_and_plot(model_gray, batch_size=4, img_size=(224, 224), channels=1)\n",
    "\n",
    "#model_load = initialize_model((224, 224, 1))\n",
    "                                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
